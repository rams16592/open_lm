accum-freq: 1
batch-size: 8
beta1: 0.9
beta2: 0.95
data-key: "json"
dataset-resampled: True
delete-previous-checkpoint: False
# Total 10B * 70 = 700B tokens
epochs: 70
ffn-type: gelu
fsdp-amp: True
fsdp: True
fsdp-limit-all-gathers: True
fused-xent: True
grad-checkpointing: True
grad-clip-norm: 1
log-every-n-steps: 20
lr-cooldown-end: 3e-5
lr: 1e-3
model-norm: "lp_layer_norm"
model: "l7b_neox"
name: "7b_gelu_fusedxent_lpln"
precision: "amp_bfloat16"
qk-norm: True
report-to: "wandb"
# resume: None
seed: 124
train-data-mix-weights: "0.725::0.275"
train-data: "openlm_mix_tri_s3"
train-num-samples: 10_000_000_000
wandb-project-name: "lm1"
warmup: 2000
wd: 0.1
workers: 4
z-loss-coefficient: 1e-4
