accum-freq: 8
batch-size: 64
beta2: 0.95
data-key: "json"
dataset-resampled: True
delete-previous-checkpoint: False
epochs: 10
fsdp-amp: False
fsdp-pure: True
fsdp: True
grad-checkpointing: True
grad-clip-norm: 1
log-every-n-steps: 20
logs: "./logs/debug"
lr-cooldown-end: 3e-5
lr: 3e-3
model-norm: "gain_only_layer_norm"
model: "open_lm_1b"
name: "debug_1b_fsdp_pure"
precision: "amp_bfloat16"
report-to: "wandb"
resume: "latest"
seed: 124
train-data-mix-weights: "0.725::0.275"
train-data: "openlm_mix_tri_s3"
train-num-samples: 14_500_000_000
wandb-project-name: "lm1"
warmup: 2000
wd: 0.1
workers: 2